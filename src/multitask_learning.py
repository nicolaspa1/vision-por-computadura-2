#!/usr/bin/env python3
"""
Extensi√≥n 2: Multi-Task Learning para Grietas
Objetivo: Detectar grietas + Clasificar severidad + Localizar regi√≥n
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from models import get_model
import numpy as np


class MultiTaskCrackModel(nn.Module):
    """Modelo multi-task para detecci√≥n de grietas con m√∫ltiples salidas"""

    def __init__(self, backbone_name='resnet18'):
        super().__init__()

        # Backbone compartido
        if backbone_name == 'resnet18':
            import torchvision.models as models
            backbone = models.resnet18(pretrained=True)
            self.features = nn.Sequential(*list(backbone.children())[:-2])  # Sin avgpool y fc
            feature_dim = 512

        # Pooling adaptativo
        self.adaptive_pool = nn.AdaptiveAvgPool2d((7, 7))

        # Cabezas de tarea espec√≠ficas

        # 1. Detecci√≥n binaria (crack/no-crack)
        self.detection_head = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Dropout(0.3),
            nn.Linear(feature_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 2)  # Binary classification
        )

        # 2. Clasificaci√≥n de severidad (4 niveles)
        self.severity_head = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Dropout(0.3),
            nn.Linear(feature_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 4)  # None, Light, Moderate, Severe
        )

        # 3. Localizaci√≥n de regi√≥n (4 cuadrantes)
        self.location_head = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Dropout(0.3),
            nn.Linear(feature_dim, 128),
            nn.ReLU(),
            nn.Linear(128, 4)  # Top-left, Top-right, Bottom-left, Bottom-right
        )

        # 4. Regresi√≥n de √°rea afectada (0-100%)
        self.area_head = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Flatten(),
            nn.Dropout(0.3),
            nn.Linear(feature_dim, 64),
            nn.ReLU(),
            nn.Linear(64, 1),
            nn.Sigmoid()  # Output 0-1
        )

    def forward(self, x):
        # Caracter√≠sticas compartidas
        features = self.features(x)  # [batch, 512, H, W]

        # M√∫ltiples salidas
        detection = self.detection_head(features)  # [batch, 2]
        severity = self.severity_head(features)  # [batch, 4]
        location = self.location_head(features)  # [batch, 4]
        area = self.area_head(features)  # [batch, 1]

        return {
            'detection': detection,
            'severity': severity,
            'location': location,
            'area': area
        }


class MultiTaskTrainer:
    """Entrenador para modelo multi-task"""

    def __init__(self, model, device='cuda'):
        self.model = model.to(device)
        self.device = device

        # Criterios de p√©rdida para cada tarea
        self.detection_criterion = nn.CrossEntropyLoss()
        self.severity_criterion = nn.CrossEntropyLoss()
        self.location_criterion = nn.CrossEntropyLoss()
        self.area_criterion = nn.MSELoss()

        # Pesos para balancear las p√©rdidas
        self.task_weights = {
            'detection': 1.0,
            'severity': 0.5,
            'location': 0.3,
            'area': 0.2
        }

    def compute_multi_task_loss(self, outputs, targets):
        """Calcular p√©rdida combinada para todas las tareas"""

        losses = {}

        # 1. P√©rdida de detecci√≥n
        losses['detection'] = self.detection_criterion(
            outputs['detection'], targets['detection']
        )

        # 2. P√©rdida de severidad (solo para im√°genes con grietas)
        if 'severity' in targets:
            losses['severity'] = self.severity_criterion(
                outputs['severity'], targets['severity']
            )
        else:
            losses['severity'] = torch.tensor(0.0, device=self.device)

        # 3. P√©rdida de localizaci√≥n (solo para im√°genes con grietas)
        if 'location' in targets:
            losses['location'] = self.location_criterion(
                outputs['location'], targets['location']
            )
        else:
            losses['location'] = torch.tensor(0.0, device=self.device)

        # 4. P√©rdida de √°rea
        if 'area' in targets:
            losses['area'] = self.area_criterion(
                outputs['area'].squeeze(), targets['area'].float()
            )
        else:
            losses['area'] = torch.tensor(0.0, device=self.device)

        # P√©rdida total ponderada
        total_loss = sum(
            self.task_weights[task] * loss
            for task, loss in losses.items()
        )

        losses['total'] = total_loss
        return losses


def create_synthetic_multilabels(data_loader):
    """Crear etiquetas sint√©ticas para multi-task learning"""

    multi_task_data = []

    for images, labels in data_loader:
        batch_size = images.shape[0]

        # Crear etiquetas multi-task sint√©ticas
        multi_labels = {
            'detection': labels,  # Original crack/no-crack
            'severity': torch.zeros(batch_size, dtype=torch.long),
            'location': torch.zeros(batch_size, dtype=torch.long),
            'area': torch.zeros(batch_size)
        }

        # Para im√°genes con grietas, generar etiquetas sint√©ticas
        for i in range(batch_size):
            if labels[i] == 1:  # Tiene grieta
                # Severidad aleatoria basada en simulaci√≥n
                multi_labels['severity'][i] = torch.randint(1, 4, (1,))  # Light, Moderate, Severe

                # Localizaci√≥n aleatoria
                multi_labels['location'][i] = torch.randint(0, 4, (1,))  # 4 cuadrantes

                # √Årea afectada (0.1 - 0.8 para grietas)
                multi_labels['area'][i] = torch.rand(1) * 0.7 + 0.1
            else:
                # Sin grieta
                multi_labels['severity'][i] = 0  # None
                multi_labels['location'][i] = 0  # N/A
                multi_labels['area'][i] = 0.0  # 0% area

        multi_task_data.append((images, multi_labels))

    return multi_task_data


def compare_single_vs_multitask():
    """Comparar enfoque single-task vs multi-task"""

    print("üî¨ COMPARACI√ìN: Single-Task vs Multi-Task Learning")
    print("=" * 60)

    # Cargar datos
    from utils import get_data_loaders
    train_loader, val_loader, test_loader = get_data_loaders('data/raw', batch_size=32)

    # Crear datos multi-task sint√©ticos
    multi_train_data = create_synthetic_multilabels(train_loader)

    print("‚úÖ Datos multi-task creados")
    print(f"üìä Tareas: Detecci√≥n + Severidad + Localizaci√≥n + √Årea")

    # Modelo multi-task
    multi_model = MultiTaskCrackModel('resnet18')
    trainer = MultiTaskTrainer(multi_model)

    print("‚úÖ Modelo multi-task configurado")
    print(f"üéØ Salidas: {multi_model(torch.randn(1, 3, 224, 224)).keys()}")

    # Comparaci√≥n te√≥rica
    comparison = {
        'single_task': {
            'objective': 'Solo detecci√≥n crack/no-crack',
            'outputs': 1,
            'complexity': 'Baja',
            'accuracy': '99.85% (actual)',
            'applications': 'Detecci√≥n simple'
        },
        'multi_task': {
            'objective': 'Detecci√≥n + Severidad + Localizaci√≥n + √Årea',
            'outputs': 4,
            'complexity': 'Alta',
            'accuracy': 'Estimado 97-99% (m√°s dif√≠cil)',
            'applications': 'An√°lisis completo de grietas'
        }
    }

    print("\nüìä COMPARACI√ìN DETALLADA:")
    print("-" * 60)
    for approach, details in comparison.items():
        print(f"\n{approach.upper()}:")
        for key, value in details.items():
            print(f"  {key}: {value}")

    return multi_model, trainer


def main():
    """Funci√≥n principal del an√°lisis multi-task"""

    print("üéØ AN√ÅLISIS MULTI-TASK LEARNING")
    print("=" * 60)

    # Comparar enfoques
    multi_model, trainer = compare_single_vs_multitask()

    # Demostraci√≥n de arquitectura
    dummy_input = torch.randn(2, 3, 224, 224)
    outputs = multi_model(dummy_input)

    print(f"\nüîç DEMOSTRACI√ìN DE SALIDAS:")
    print("-" * 40)
    for task, output in outputs.items():
        print(f"{task}: {output.shape}")

    print(f"\nüí° INSIGHTS MULTI-TASK:")
    print("‚úÖ Aprovecha caracter√≠sticas compartidas")
    print("‚úÖ Una sola red para m√∫ltiples an√°lisis")
    print("‚úÖ M√°s informaci√≥n por inferencia")
    print("‚ö†Ô∏è Mayor complejidad de entrenamiento")
    print("‚ö†Ô∏è Requiere etiquetas m√°s ricas")

    return multi_model


if __name__ == "__main__":
    main()